<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Short on junuxyz</title>
    <link>https://junuxyz.github.io/tags/short/</link>
    <description>Recent content in Short on junuxyz</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Sep 2025 11:13:40 +0900</lastBuildDate>
    <atom:link href="https://junuxyz.github.io/tags/short/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Limitations of Current RL</title>
      <link>https://junuxyz.github.io/posts/limitations-of-current-rl/</link>
      <pubDate>Wed, 03 Sep 2025 11:13:40 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/limitations-of-current-rl/</guid>
      <description>&lt;p&gt;Just read the paper &lt;em&gt;Welcome to the Era of Experience&lt;/em&gt; by Richard S. Sutton and David Silver, and while I admit the potential impact RL will have, Iâ€™m pretty concerned about what these authors believe or are trying to create.&lt;/p&gt;&#xA;&lt;p&gt;I believe AI in general needs to be controlled and understood by humans as much as possible, especially for making important and impactful judgments. However, RL lacks this understandability and controllability because of its unexplainable, black-box decision mechanism. It simply makes choices that will gain the maximum reward based on the reward function we define.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Engineering Era of AI</title>
      <link>https://junuxyz.github.io/posts/the-engineering-era-of-ai/</link>
      <pubDate>Sat, 30 Aug 2025 14:02:26 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/the-engineering-era-of-ai/</guid>
      <description>&lt;p&gt;I feel like the trend of AI is shifting from model construct/pre-training to post-training/pipelining/engineering phase, which we use system-level knowledge to implement the model the fastest, efficient as possible.&lt;/p&gt;&#xA;&lt;p&gt;Of course new models/architectures(world models, System 2, GFlowNet, JEPA etc.), domains(robotics, biology etc.), and paradigms(Reinforcement Learning, Energy based models etc) will come but after all, the &amp;ldquo;verification&amp;rdquo; phase of AI seems done after the huge success and impact of ChatGPT.&lt;/p&gt;&#xA;&lt;p&gt;Now deployment to real world use is getting larger and larger. Big tech companies and AI startups are already noticing and are working on this (&lt;a href=&#34;https://openai.com/index/triton/&#34;&gt;more efficient LLM inference&lt;/a&gt;, faster and better image/video generation (e.g. &lt;a href=&#34;https://blog.google/products/gemini/updated-image-editing-model/&#34;&gt;Nano Banana&lt;/a&gt;), &lt;a href=&#34;https://developer.nvidia.com/isaac/lab&#34;&gt;Robot Learning simulation&lt;/a&gt;, and &lt;a href=&#34;https://www.meta.com/kr/en/ai-glasses/&#34;&gt;smart glasses&lt;/a&gt;) a lot on this. Still I think A LOT MORE are about to be deployed in various fields in various forms in the upcoming years.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mental Model of Engineering</title>
      <link>https://junuxyz.github.io/posts/mental-model-of-engineering/</link>
      <pubDate>Mon, 04 Aug 2025 14:43:35 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/mental-model-of-engineering/</guid>
      <description>&lt;h3 id=&#34;the-process&#34;&gt;The Process&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Define and Identify the problem.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can you define and express the problem in numbers? (e.g. computing speed is so slow it takes more than 10 minutes to do x, this method has 20% more memory usage than the other method etc.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/YFUVMPOIeAo?si=ba_aXfU1Ge3GpRWR&#34;&gt;Think if that problem is even worth solving&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Analyze the root cause of the problem&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What &lt;em&gt;exactly&lt;/em&gt; is the problem? Find the root cause&lt;/li&gt;&#xA;&lt;li&gt;Why do you think it&amp;rsquo;s a problem?&lt;/li&gt;&#xA;&lt;li&gt;Find where the bottleneck lies.&lt;/li&gt;&#xA;&lt;li&gt;Understand the mechanism (what goes under the hood?): input and output&lt;/li&gt;&#xA;&lt;li&gt;Complicated domains and subjects are mostly due to multiple layers of abstraction.&lt;/li&gt;&#xA;&lt;li&gt;Keep dividing until you narrow down to the core reason.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Solution Design&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>The I/O and Pipelining Era of ML</title>
      <link>https://junuxyz.github.io/posts/the-io-and-pipelining-era-of-ml/</link>
      <pubDate>Fri, 01 Aug 2025 16:00:15 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/the-io-and-pipelining-era-of-ml/</guid>
      <description>&lt;p&gt;Back in the days, constructing and finding novel neural networks(like CNN, RNN, GAN and many more) and scaling it to become &amp;ldquo;deeper&amp;rdquo; was the trend in Deep Learning research.&lt;/p&gt;&#xA;&lt;p&gt;After Transformers came out and as researchers noticed the power of Transformers, I feel the research trend shifted a lot into industrial and engineering problems. Yes, there were and are still some researches focusing on new architectures (like &lt;a href=&#34;https://arxiv.org/abs/2312.00752&#34;&gt;Mamba&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2501.00663&#34;&gt;Titans&lt;/a&gt; etc) but in general I feel the trend has changed.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
