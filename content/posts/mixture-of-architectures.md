+++
title = "MoA(Mixture of Architectures)"
date = 2025-08-25T15:04:56+09:00
draft = true
categories = ['Thoughts']
+++


![[moa-1.png]]

Just watched a [video](https://www.youtube.com/watch?v=p1QXZHV4jkM) about Yann Lecun's point of view on LLMs and his new architecture V-JEPA.

While I agree LLMs alone won't lead to AGI or ASI, I don't totally agree of his point of view. I mean, I don't understand why researchers are only trying to seek a unified solution. Maybe that can be possible but for now, I see all these AI paradigms and systems useful in their own ways.

LLMs with post-training can have conversation and interact with human. It's easier to interact with, and while we don't understand the mechanism, we can fully understand the output because it is in lanugage. However they lack of novelty or superhuman level intelligence because after all, they are trained by human data.

Reinforcement Learning on the other hand is highly inefficient, unreliable, less scalable, harder to explain what's happening under the hood than LLMs but they find novel solutions no human ever made in narrow, specific, domains that have appropriate metric, reward functions, and well defined action spaces. (ex. AlphaGo, AlphaZero, AlphaDev etc.)

Comment in the video I watched resonated with my thoughts of "Mixture of Architectures". GPT Store (now GPTs) showed a Proof of concept of this.