<!doctype html><html lang=en-us class=theme-auto><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>The I/O and Pipelining Era of ML - junuxyz</title><meta name=description content="Personal blog and thoughts"><meta name=author content="Junu"><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=icon type=image/x-icon href=/favicon.ico><script>const theme=localStorage.getItem("theme")||"auto";(theme==="dark"||theme==="auto"&&window.matchMedia("(prefers-color-scheme: dark)").matches)&&document.documentElement.classList.add("dark")</script></head><body><header class=header><div class=header-content><div class=logo><a href=https://junuxyz.github.io/>junuxyz</a></div><div class=header-right><nav class=nav><a href=/categories/thoughts/ class=nav-item>Thoughts</a>
<a href=/categories/ml/ class=nav-item>ML</a>
<a href=/about/ class=nav-item>About</a>
<a href=/tags/ class=nav-item>Tags</a></nav><button id=theme-toggle type=button aria-label="Toggle theme">
<svg class="sun-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
<svg class="moon-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></button></div></div></header><main class=main><div class=container><article class=post><header class=post-header><h1 class=post-title>The I/O and Pipelining Era of ML</h1><div class=post-meta><time datetime=2025-08-01T16:00:15+09:00>August 1, 2025</time><div class=post-tags><a href=/tags/short/ class=tag>#short</a></div></div></header><div class=post-content><p>Back in the days, constructing and finding novel neural networks(like CNN, RNN, GAN and many more) and scaling it to become &ldquo;deeper&rdquo; was the trend in Deep Learning research.</p><p>After Transformers came out and as researchers noticed the power of Transformers, I feel the research trend shifted a lot into industrial and engineering problems. Yes, there were and are still some researches focusing on new architectures (like <a href=https://arxiv.org/abs/2312.00752>Mamba</a>, <a href=https://arxiv.org/abs/2501.00663>Titans</a> etc) but in general I feel the trend has changed.</p><p>Especially after the &ldquo;ChatGPT moment&rdquo; researchers are working on how to efficiently optimize and deploy transformers to serve them in low cost, low latency, and high accuracy. I am not sure if this will be a short term trend after another novel state-of-the-art architecture comes out or another paradigm appears beyond LLMs as <a href=https://x.com/ylecun/status/1911604721267114206>Yann LeCun said</a> (e.g. World Model, Robotics etc).</p><p>I feel at least in the near term the trend of efficiency and engineering will prevail.
Frameworks like <a href=https://github.com/sgl-project/sglang>SGLang</a>, <a href=https://github.com/vllm-project/vllm>vLLM</a> and optimization techniques of Transformers such as <a href=https://arxiv.org/abs/2309.06180>PagedAttention</a>, <a href=https://github.com/Dao-AILab/flash-attention>FlashAttention</a> and tools like <a href=https://github.com/triton-lang/triton>Triton</a> and <a href=https://en.wikipedia.org/wiki/CUDA>CUDA</a> programming are getting much traction than few years before.</p><p>If I am thinking in the right direction, the mental model should be focused on <strong>I/O and pipelining</strong>.</p><p>This means we need to understand</p><ul><li>how each process of training and deploying are done</li><li>why does each steps even exist (can we reduce the steps?)</li><li>what inputs produces what outputs</li><li>identify the underlying bottleneck (cost of time or latency etc) and optimize it.</li></ul></div><nav class=post-nav><div class=nav-prev><a href=https://junuxyz.github.io/posts/what-i-like-what-i-dislike-what-i-want-to-be/ class=nav-link><span class=nav-label>← Previous</span>
<span class=nav-title>What I Like and What I Don't</span></a></div><div class=nav-next><a href=https://junuxyz.github.io/posts/ideas-im-interested-in-ai/ class=nav-link><span class=nav-label>Next →</span>
<span class=nav-title>Ideas I'm interested in AI (Research & Field)</span></a></div></nav></article></div></main><footer class=footer><div class=footer-content><p>&copy; 2025 junuxyz. Built with <a href=https://gohugo.io/>Hugo</a>.</p></div></footer><script src=/js/theme.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></body></html>