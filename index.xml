<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>junuxyz</title>
    <link>https://junuxyz.github.io/</link>
    <description>Recent content on junuxyz</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 20 Jul 2025 16:26:31 +0900</lastBuildDate>
    <atom:link href="https://junuxyz.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lab01: Adding Vector</title>
      <link>https://junuxyz.github.io/posts/lab01-adding-vector/</link>
      <pubDate>Sun, 20 Jul 2025 16:26:31 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/lab01-adding-vector/</guid>
      <description>&lt;p&gt;This is a simple experiment to just get a feel of the abstraction PyTorch provides, and all the internal complexity hidden below. We will also compare the performance of basic vector addition between PyTorch, Triton, and CUDA.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: This experiment was done in NVIDIA RTX 3050ti laptop GPU&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;vector-addition-in-pytorch&#34;&gt;Vector Addition in PyTorch&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(size, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(size, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;empty_like(a)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PyTorch output:&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(output)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;empty_like(a)&lt;/code&gt; creates the same size, dtype, and device(&amp;lsquo;cuda&amp;rsquo;) as the input tensor &lt;code&gt;a&lt;/code&gt;. It does not initialize the memory into something else, but use the garbage value of it so it&amp;rsquo;s a bit faster than using &lt;code&gt;torch.zeros()&lt;/code&gt; or &lt;code&gt;torch.ones()&lt;/code&gt;.&#xA;The exact operation of vector addition is hidden in operator &lt;code&gt;+&lt;/code&gt; in PyTorch.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h3 id=&#34;vector-addition-in-triton&#34;&gt;Vector Addition in Triton&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/triton-lang/triton&#34;&gt;Triton&lt;/a&gt; is an open source library ran by OpenAI, which aims to be easier to code than CUDA (fewer knobs to control, don&amp;rsquo;t need to know as deep as CUDA) but doesn&amp;rsquo;t lose the performance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A (shallow) Dive into VSCode Debugger</title>
      <link>https://junuxyz.github.io/posts/a-shallow-dive-into-vscode-debugger/</link>
      <pubDate>Wed, 16 Jul 2025 21:45:17 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/a-shallow-dive-into-vscode-debugger/</guid>
      <description>&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;&#xA;&lt;p&gt;I know debugging skills are very important and one of the &amp;ldquo;must have&amp;rdquo; skills for developers. However I did not explicitly tried to learn how to use and utilize VSCode debugger effectively. While reading &lt;a href=&#34;https://www.learncpp.com/cpp-tutorial/using-an-integrated-debugger-stepping/&#34;&gt;this&lt;/a&gt; during my entry to c++, I thought now was the right time to look into features VS Code gives, which were worth note taking. Today is just a shallow dive and hope to learn deeper when I need it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Not Regret</title>
      <link>https://junuxyz.github.io/posts/how-to-not-regret/</link>
      <pubDate>Sat, 28 Jun 2025 09:00:12 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/how-to-not-regret/</guid>
      <description>&lt;p&gt;Today, I am going to talk about how to not regret. This is important to many of us, since we spend lots of time regretting our past, suffering about the future, and blaming our current selves.&lt;/p&gt;&#xA;&lt;p&gt;The answer to this is quite straightforward: &lt;strong&gt;Do your best in the given situation.&lt;/strong&gt; I know, it sounds predictable and perhaps a bit clich√©, but please, keep reading. You think you&amp;rsquo;ve failed and lost too many good chances? It doesn&amp;rsquo;t matter; the answer remains the same: &lt;strong&gt;Do your best in the given situation.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Useful Mental Model on How to Build Your Unique Career</title>
      <link>https://junuxyz.github.io/posts/a-useful-mental-model-on-how-to-build-your-unique-career/</link>
      <pubDate>Sat, 08 Mar 2025 00:00:00 +0900</pubDate>
      <guid>https://junuxyz.github.io/posts/a-useful-mental-model-on-how-to-build-your-unique-career/</guid>
      <description>&lt;p&gt;If you want to be a pro, imagine the job role or the company you want to get in. Google, Tesla, Facebook, Apple, etc&amp;hellip; logically you need to work as much or harder than that everyday.&lt;/p&gt;&#xA;&lt;p&gt;Then, what should you work on?&lt;/p&gt;&#xA;&lt;p&gt;Hard problems; the problems people are facing in the domain.&lt;/p&gt;&#xA;&lt;p&gt;Find out and contemplate on&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;what the problem is&lt;/li&gt;&#xA;&lt;li&gt;why it&amp;rsquo;s a problem&lt;/li&gt;&#xA;&lt;li&gt;what have been done to solve the problem&lt;/li&gt;&#xA;&lt;li&gt;why those problems don&amp;rsquo;t work&lt;/li&gt;&#xA;&lt;li&gt;what can be done to solve that problem&lt;/li&gt;&#xA;&lt;li&gt;why that can be a candidate logically (rationally)&lt;/li&gt;&#xA;&lt;li&gt;and do it&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://junuxyz.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://junuxyz.github.io/about/</guid>
      <description>&lt;p&gt;Hi I&amp;rsquo;m Junu.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
