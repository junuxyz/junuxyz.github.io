<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Limitations of Current RL - jlog</title><meta name=description content="Personal blog and thoughts"><meta name=author content="Junu"><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link rel=stylesheet href=/css/custom.css><link rel=icon type=image/x-icon href=/favicon.ico></head><body class=blog-section><header class=header><div class=header-content><div class=logo><a href=/blog/>jlog</a></div><div class=header-right><nav class=nav><a href=/blog/categories/thoughts/ class=nav-item>Thoughts</a>
<a href=/blog/categories/ml/ class=nav-item>ML</a>
<a href=/blog/about/ class=nav-item>About</a>
<a href=/blog/tags/ class=nav-item>Tags</a></nav></div></div></header><main class=main><div class=container><article class=post><header class=post-header><h1 class=post-title>Limitations of Current RL</h1><div class=post-meta><time datetime=2025-09-03T11:13:40+09:00>September 3, 2025</time><div class=post-tags><a href=/blog/tags/short/ class=tag>#short</a></div></div></header><div class=post-content><p>Just read the paper <em>Welcome to the Era of Experience</em> by Richard S. Sutton and David Silver, and while I admit the potential impact RL will have, I’m pretty concerned about what these authors believe or are trying to create.</p><p>I believe AI in general needs to be controlled and understood by humans as much as possible, especially for making important and impactful judgments. However, RL lacks this understandability and controllability because of its unexplainable, black-box decision mechanism. It simply makes choices that will gain the maximum reward based on the reward function we define.</p><p>We don’t know the intermediate steps (or if those kinds of <em>steps</em> even exist), which makes it highly unreliable and almost impossible to understand. We also cannot guarantee whether it is aligned with users or not. Even if it’s aligned with humans, for domains that do NOT have obvious metrics (e.g., feelings or emotions) the results might become highly unreliable. Lastly, even if we somehow make the model capable of assessing human feelings and pleasing that person, I’m not sure if that is fundamentally <em>good</em> for us. Since humans are prone to immediate pleasure over long-term gain/well-being, AI’s attempt to please us or manipulate us could negatively affect us.</p><p>So while I believe RL has the potential to enable novel developments and breakthroughs within science and technology where metrics can be quantified and observed more objectively, I don’t think RL alone is the way to AGI/ASI (too expensive, too unreliable).</p><p>I believe it will do GREAT in code generation (finding new algorithms), chip design, scientific discovery (e.g., biology), gaming, and finding strategies for well-defined A-to-B problems, and I am very excited about it. However, beyond that, value-related applications seem too dangerous.</p><p>For the same reason, I think AI agents and robot learning should be based on more explainable systems such as VLA (Vision–Language–Action) rather than RL, since VLA is more scalable, reliable, and understandable. While I am skeptical about current RL, maybe there will be a breakthrough in reliable, aligned RL which I am looking forward to.</p></div><nav class=post-nav><div class=nav-prev><a href=/blog/posts/the-engineering-era-of-ai/ class=nav-link><span class=nav-label>previous: </span><span class=nav-title>The Engineering Era of AI</span></a></div><div class=nav-next><a href=/blog/posts/shaped-transformer/ class=nav-link><span class=nav-label>next: </span><span class=nav-title>Shaped Transformer</span></a></div></nav></article></div></main><footer class=footer><div class=footer-content><p>&copy; 2025 jlog. Built with <a href=https://gohugo.io/>Hugo</a>.</p></div></footer><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll("pre code").forEach(e=>{const t=e.parentElement;if(!t.querySelector(".code-copy-btn")){const n=document.createElement("button");n.className="code-copy-btn",n.textContent="Copy",n.setAttribute("aria-label","Copy code to clipboard"),n.addEventListener("click",()=>{navigator.clipboard.writeText(e.textContent).then(()=>{n.textContent="Copied!",n.classList.add("copied"),setTimeout(()=>{n.textContent="Copy",n.classList.remove("copied")},2e3)})}),t.style.position="relative",t.appendChild(n)}if(!t.querySelector(".code-language")){let n=e.getAttribute("data-lang");if(!n){const t=(e.className||"").match(/language-([^\s]+)/);t&&t[1]&&(n=t[1])}if(n){const e=document.createElement("span");e.className="code-language",e.textContent=n.charAt(0).toUpperCase()+n.slice(1),t.appendChild(e)}}}),renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></body></html>