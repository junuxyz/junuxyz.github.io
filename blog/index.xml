<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>All Posts on jlog</title>
    <link>https://junuxyz.github.io/blog/</link>
    <description>Recent content in All Posts on jlog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Sep 2025 11:13:40 +0900</lastBuildDate>
    <atom:link href="https://junuxyz.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Limitations of Current RL</title>
      <link>https://junuxyz.github.io/blog/posts/limitations-of-current-rl/</link>
      <pubDate>Wed, 03 Sep 2025 11:13:40 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/limitations-of-current-rl/</guid>
      <description>&lt;p&gt;Just read the paper &lt;em&gt;Welcome to the Era of Experience&lt;/em&gt; by Richard S. Sutton and David Silver, and while I admit the potential impact RL will have, I’m pretty concerned about what these authors believe or are trying to create.&lt;/p&gt;&#xA;&lt;p&gt;I believe AI in general needs to be controlled and understood by humans as much as possible, especially for making important and impactful judgments. However, RL lacks this understandability and controllability because of its unexplainable, black-box decision mechanism. It simply makes choices that will gain the maximum reward based on the reward function we define.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Engineering Era of AI</title>
      <link>https://junuxyz.github.io/blog/posts/the-engineering-era-of-ai/</link>
      <pubDate>Sat, 30 Aug 2025 14:02:26 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/the-engineering-era-of-ai/</guid>
      <description>&lt;p&gt;I feel like the trend of AI is shifting from model construct/pre-training to post-training/pipelining/engineering phase, which we use system-level knowledge to implement the model the fastest, efficient as possible.&lt;/p&gt;&#xA;&lt;p&gt;Of course new models/architectures(world models, System 2, GFlowNet, JEPA etc.), domains(robotics, biology etc.), and paradigms(Reinforcement Learning, Energy based models etc) will come but after all, the &amp;ldquo;verification&amp;rdquo; phase of AI seems done after the huge success and impact of ChatGPT.&lt;/p&gt;&#xA;&lt;p&gt;Now deployment to real world use is getting larger and larger. Big tech companies and AI startups are already noticing and are working on this (&lt;a href=&#34;https://openai.com/index/triton/&#34;&gt;more efficient LLM inference&lt;/a&gt;, faster and better image/video generation (e.g. &lt;a href=&#34;https://blog.google/products/gemini/updated-image-editing-model/&#34;&gt;Nano Banana&lt;/a&gt;), &lt;a href=&#34;https://developer.nvidia.com/isaac/lab&#34;&gt;Robot Learning simulation&lt;/a&gt;, and &lt;a href=&#34;https://www.meta.com/kr/en/ai-glasses/&#34;&gt;smart glasses&lt;/a&gt;) a lot on this. Still I think A LOT MORE are about to be deployed in various fields in various forms in the upcoming years.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Review] UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representation</title>
      <link>https://junuxyz.github.io/blog/posts/uniskill/</link>
      <pubDate>Tue, 26 Aug 2025 13:04:39 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/uniskill/</guid>
      <description>&lt;img src=&#34;https://junuxyz.github.io/images/unkskill.png&#34; alt=&#34;Image&#34;&gt;&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;&#xA;&lt;p&gt;Imitating experts is challenging due to visual, physical differences between human and robot.&lt;/p&gt;&#xA;&lt;p&gt;Previous methods used cross-embodiment datasets with shared scenes and tasks but these data are limited which makes it hard to scale.&lt;/p&gt;&#xA;&lt;p&gt;This paper presents a new framework called &lt;strong&gt;UniSkill&lt;/strong&gt; that learns embodiment-agnostic skill representation from large video dataset.&lt;/p&gt;&#xA;&lt;h1 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h1&gt;&#xA;&lt;p&gt;UniSkill uses image-editing pipeline for the neural network to focus on capturing the dynamics changes (over static content) between temproally distant video frames.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lab02: Deploying DialoGPT-Medium with FastAPI &amp; Docker</title>
      <link>https://junuxyz.github.io/blog/posts/lab02-deploying-dialo-gpt-with-fastapi/</link>
      <pubDate>Wed, 20 Aug 2025 15:57:15 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/lab02-deploying-dialo-gpt-with-fastapi/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In Lab02, We are going to look at how Jupyter/Colab Notebook models, codes are actually deployed as a service.&lt;/p&gt;&#xA;&lt;img src=&#34;https://junuxyz.github.io/images/simple-chat.png&#34; alt=&#34;Image&#34;&gt;&lt;p&gt;This is a simple chatbot called &lt;em&gt;simple chat&lt;/em&gt; which is containerized in Docker and run on FastAPI.&lt;/p&gt;&#xA;&lt;p&gt;We will build and deploy this chatbot using DialoGPT as the model, use FastAPI to create API endpoints, and deploy it with Docker.&lt;/p&gt;&#xA;&lt;p&gt;The goal of this lab is to experience the end-to-end of deploying and serving a LLM model from scratch, with minimal configuration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mental Model of Engineering</title>
      <link>https://junuxyz.github.io/blog/posts/mental-model-of-engineering/</link>
      <pubDate>Mon, 04 Aug 2025 14:43:35 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/mental-model-of-engineering/</guid>
      <description>&lt;h3 id=&#34;the-process&#34;&gt;The Process&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Define and Identify the problem.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can you define and express the problem in numbers? (e.g. computing speed is so slow it takes more than 10 minutes to do x, this method has 20% more memory usage than the other method etc.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/YFUVMPOIeAo?si=ba_aXfU1Ge3GpRWR&#34;&gt;Think if that problem is even worth solving&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Analyze the root cause of the problem&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What &lt;em&gt;exactly&lt;/em&gt; is the problem? Find the root cause&lt;/li&gt;&#xA;&lt;li&gt;Why do you think it&amp;rsquo;s a problem?&lt;/li&gt;&#xA;&lt;li&gt;Find where the bottleneck lies.&lt;/li&gt;&#xA;&lt;li&gt;Understand the mechanism (what goes under the hood?): input and output&lt;/li&gt;&#xA;&lt;li&gt;Complicated domains and subjects are mostly due to multiple layers of abstraction.&lt;/li&gt;&#xA;&lt;li&gt;Keep dividing until you narrow down to the core reason.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Solution Design&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ideas I&#39;m interested in AI (Research &amp; Field)</title>
      <link>https://junuxyz.github.io/blog/posts/ideas-im-interested-in-ai/</link>
      <pubDate>Fri, 01 Aug 2025 16:59:45 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/ideas-im-interested-in-ai/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;high (abstract) level pattern recognition&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;understanding the underlying message despite of words and content, just the underlying message etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;overcoming data bottleneck&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;data is the fossil fuel of AI but we have only one Internet - Ilya Sutskever&lt;/li&gt;&#xA;&lt;li&gt;how can we create more data?&#xA;&lt;ul&gt;&#xA;&lt;li&gt;new sort of data&lt;/li&gt;&#xA;&lt;li&gt;synthetic data&lt;/li&gt;&#xA;&lt;li&gt;RLHF and DPO&lt;/li&gt;&#xA;&lt;li&gt;metrifying subjective information&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;how to deploy static models in dynamic world&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;continuous learning&lt;/li&gt;&#xA;&lt;li&gt;are our mental models also static? Maybe we think statically, too (based on our past knowledge and experience)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;how to make models more reliable&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>The I/O and Pipelining Era of ML</title>
      <link>https://junuxyz.github.io/blog/posts/the-io-and-pipelining-era-of-ml/</link>
      <pubDate>Fri, 01 Aug 2025 16:00:15 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/the-io-and-pipelining-era-of-ml/</guid>
      <description>&lt;p&gt;Back in the days, constructing and finding novel neural networks(like CNN, RNN, GAN and many more) and scaling it to become &amp;ldquo;deeper&amp;rdquo; was the trend in Deep Learning research.&lt;/p&gt;&#xA;&lt;p&gt;After Transformers came out and as researchers noticed the power of Transformers, I feel the research trend shifted a lot into industrial and engineering problems. Yes, there were and are still some researches focusing on new architectures (like &lt;a href=&#34;https://arxiv.org/abs/2312.00752&#34;&gt;Mamba&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2501.00663&#34;&gt;Titans&lt;/a&gt; etc) but in general I feel the trend has changed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What I Like and What I Don&#39;t</title>
      <link>https://junuxyz.github.io/blog/posts/what-i-like-what-i-dislike-what-i-want-to-be/</link>
      <pubDate>Tue, 29 Jul 2025 22:29:14 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/what-i-like-what-i-dislike-what-i-want-to-be/</guid>
      <description>&lt;h3 id=&#34;what-i-like&#34;&gt;What I Like&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Deep focused life&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;because I feel most satisfied and happy when I&amp;rsquo;m in a state of deep focus (or &lt;em&gt;flow&lt;/em&gt;). When I&amp;rsquo;m not immersed and my mind wanders, I just end up with pointless anxieties.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;How to achieve&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Time is limited so pick carefully what to do.&lt;/li&gt;&#xA;&lt;li&gt;Delete elements that are harmful for the flow state.&lt;/li&gt;&#xA;&lt;li&gt;Optimize or delegate things that are not related to my core interest but are needed in regular basis (ex. meal, workout, life habits, and chores etc.)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Best way to optimize is to make principles.&lt;/li&gt;&#xA;&lt;li&gt;Principles are means and we must have purpose for it. When this is misleaded and following the principles itself becomes a purpose, innovation stops. Then inefficiency and distrust increases.&lt;/li&gt;&#xA;&lt;li&gt;Similarly, optimization is not for the sake of optimization. It&amp;rsquo;s to focus on the core values I believe in limited amount of time. Pre-optimization for things that may not be used in the future might be an inefficient thing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Make my own &lt;em&gt;game&lt;/em&gt;.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is a good game? There is a whole lot to think about this but I&amp;rsquo;ll keep it short for now.&lt;/li&gt;&#xA;&lt;li&gt;It is more robust to set the definition of &lt;em&gt;winning&lt;/em&gt; on internal reward than external reward.&lt;/li&gt;&#xA;&lt;li&gt;Definition of winning should be &lt;em&gt;measurable&lt;/em&gt; because &lt;a href=&#34;https://www.growthink.com/content/two-most-important-quotes-business&#34;&gt;you can&amp;rsquo;t manage what you can&amp;rsquo;t measure&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Leverage habits.&lt;/li&gt;&#xA;&lt;li&gt;Being impulsive harms flow state. However, since I am an impulsive person, I should make system that will handle the risk of ruining my life&amp;rsquo;s priority.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;br&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Exciting life&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>At its core, AI is about finding patterns</title>
      <link>https://junuxyz.github.io/blog/posts/at-its-core-ai-is-about-finding-patterns/</link>
      <pubDate>Tue, 29 Jul 2025 13:12:50 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/at-its-core-ai-is-about-finding-patterns/</guid>
      <description>&lt;p&gt;&lt;em&gt;Written in 2023-10-01. Just wanted to archive my old thoughts.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Today I watched a &lt;a href=&#34;https://youtu.be/CUnVY5IBvBA?si=IdfcA71fR3JtVfnP&#34;&gt;video&lt;/a&gt; and what struck me the most was this insight: &lt;strong&gt;In the end, what AI does is pattern recognition.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;“If I had to explain what AI does in one sentence, I’d say: &lt;strong&gt;AI discovers latent patterns.&lt;/strong&gt;&lt;br&gt;&#xA;In any domain where such latent patterns exist, AI will soon surpass human ability—and eventually replace humans.”&#xA;&lt;em&gt;From the video&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;This might sound like an oversimplification, but I believe one of the main reasons humans have progressed this far is our ability to &lt;strong&gt;recognize and classify patterns.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fluent Python Cheat Sheet for Newbies</title>
      <link>https://junuxyz.github.io/blog/posts/fluent-python-cheat-sheet/</link>
      <pubDate>Tue, 22 Jul 2025 18:50:06 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/fluent-python-cheat-sheet/</guid>
      <description>&lt;p&gt;High-level ML frameworks and libraries (e.g., PyTorch, JAX, TensorFlow, NumPy, Triton, and many more) are mostly based on Python.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve known Python for a while, but I&amp;rsquo;ve never learned it to a professional degree and wouldn&amp;rsquo;t say I&amp;rsquo;m good at Python programming. So, I decided to read &lt;em&gt;Fluent Python&lt;/em&gt; (which seems to be one of the &amp;lsquo;bible&amp;rsquo; figures of Python) to cover some topics and improve my Python programming skills.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lab01: Adding Vector</title>
      <link>https://junuxyz.github.io/blog/posts/lab01-adding-vector/</link>
      <pubDate>Sun, 20 Jul 2025 16:26:31 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/lab01-adding-vector/</guid>
      <description>&lt;p&gt;This is a simple experiment to just get a feel of the abstraction PyTorch provides, and all the internal complexity hidden below. We will also compare the performance of basic vector addition between PyTorch, Triton, and CUDA.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Note: This experiment was done in NVIDIA RTX 3050ti laptop GPU&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;vector-addition-in-pytorch&#34;&gt;Vector Addition in PyTorch&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;empty_like&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;PyTorch output:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;empty_like(a)&lt;/code&gt; creates the same size, dtype, and device(&amp;lsquo;cuda&amp;rsquo;) as the input tensor &lt;code&gt;a&lt;/code&gt;. It does not initialize the memory into something else, but use the garbage value of it so it&amp;rsquo;s a bit faster than using &lt;code&gt;torch.zeros()&lt;/code&gt; or &lt;code&gt;torch.ones()&lt;/code&gt;.&#xA;The exact operation of vector addition is hidden in operator &lt;code&gt;+&lt;/code&gt; in PyTorch.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;h3 id=&#34;vector-addition-in-triton&#34;&gt;Vector Addition in Triton&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/triton-lang/triton&#34;&gt;Triton&lt;/a&gt; is an open source library ran by OpenAI, which aims to be easier to code than CUDA (fewer knobs to control, don&amp;rsquo;t need to know as deep as CUDA) but doesn&amp;rsquo;t lose the performance. Check out more information via &lt;a href=&#34;https://openai.com/index/triton/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Trying Out uv as my new package managing tool</title>
      <link>https://junuxyz.github.io/blog/posts/uv/</link>
      <pubDate>Sun, 20 Jul 2025 00:06:57 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/uv/</guid>
      <description>&lt;p&gt;Dependency hell is a known problem in Machine Learning ecosystem. Hardware(eg. NVIDIA RTX chips) with major libraries such as PyTorch, NumPy etc. can easily create all sorts of dependency issues. That is why making a system for maximum reproducability is important.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve previously used poetry or conda for package managing for Python but found it hard and clunky to use sometimes. Recently I&amp;rsquo;ve found a rising tool for package managing called &lt;a href=&#34;https://github.com/astral-sh/uv/&#34;&gt;uv&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A (shallow) Dive into VSCode Debugger</title>
      <link>https://junuxyz.github.io/blog/posts/a-shallow-dive-into-vscode-debugger/</link>
      <pubDate>Wed, 16 Jul 2025 21:45:17 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/a-shallow-dive-into-vscode-debugger/</guid>
      <description>&lt;p&gt;I know debugging skills are very important and one of the &amp;ldquo;must have&amp;rdquo; skills for developers. However I did not explicitly tried to learn how to use and utilize VSCode debugger effectively. While reading &lt;a href=&#34;https://www.learncpp.com/cpp-tutorial/using-an-integrated-debugger-stepping/&#34;&gt;this&lt;/a&gt; during my entry to c++, I thought now was the right time to look into features VS Code gives, which were worth note taking. Today is just a shallow dive and hope to learn deeper when I need it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Not Regret</title>
      <link>https://junuxyz.github.io/blog/posts/how-to-not-regret/</link>
      <pubDate>Sat, 28 Jun 2025 09:00:12 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/how-to-not-regret/</guid>
      <description>&lt;p&gt;Today, I am going to talk about how to not regret. This is important to many of us, since we spend lots of time regretting our past, suffering about the future, and blaming our current selves.&lt;/p&gt;&#xA;&lt;p&gt;The answer to this is quite straightforward: &lt;strong&gt;Do your best in the given situation.&lt;/strong&gt; I know, it sounds predictable and perhaps a bit cliché, but please, keep reading. You think you&amp;rsquo;ve failed and lost too many good chances? It doesn&amp;rsquo;t matter; the answer remains the same: &lt;strong&gt;Do your best in the given situation.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Useful Mental Model on How to Build Your Unique Career</title>
      <link>https://junuxyz.github.io/blog/posts/a-useful-mental-model-on-how-to-build-your-unique-career/</link>
      <pubDate>Sat, 08 Mar 2025 00:00:00 +0900</pubDate>
      <guid>https://junuxyz.github.io/blog/posts/a-useful-mental-model-on-how-to-build-your-unique-career/</guid>
      <description>&lt;p&gt;If you want to be a pro, imagine the job role or the company you want to get in. Google, Tesla, Facebook, Apple, etc&amp;hellip; logically you need to work as much or harder than that everyday.&lt;/p&gt;&#xA;&lt;p&gt;Then, what should you work on?&lt;/p&gt;&#xA;&lt;p&gt;Hard problems; the problems people are facing in the domain.&lt;/p&gt;&#xA;&lt;p&gt;Find out and contemplate on&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;what the problem is&lt;/li&gt;&#xA;&lt;li&gt;why it&amp;rsquo;s a problem&lt;/li&gt;&#xA;&lt;li&gt;what have been done to solve the problem&lt;/li&gt;&#xA;&lt;li&gt;why those problems don&amp;rsquo;t work&lt;/li&gt;&#xA;&lt;li&gt;what can be done to solve that problem&lt;/li&gt;&#xA;&lt;li&gt;why that can be a candidate logically (rationally)&lt;/li&gt;&#xA;&lt;li&gt;and do it&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
